{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting all the malayalam chars\n",
    "malayalam_chars = [chr(code) for code in range(0x0D00, 0x0D7F + 1)]\n",
    "malayalam_chars[:10], malayalam_chars[-10:], len(malayalam_chars)\n",
    "\n",
    "# Creating a better version including full consonant × vowel sign syllable vocabulary (like ക, കാ, കി, കീ … for every consonant)\n",
    "consonants = [chr(c) for c in range(0x0D15, 0x0D39 + 1)] # basic chars\n",
    "vowel_signs = {\n",
    "    \"ാ\": \"aa\",\n",
    "    \"ി\": \"i\",\n",
    "    \"ീ\": \"ii\",\n",
    "    \"ു\": \"u\",\n",
    "    \"ൂ\": \"uu\",\n",
    "    \"ൃ\": \"r̥\",\n",
    "    \"െ\": \"e\",\n",
    "    \"േ\": \"ee\",\n",
    "    \"ൈ\": \"ai\",\n",
    "    \"ൊ\": \"o\",\n",
    "    \"ോ\": \"oo\",\n",
    "    \"ൌ\": \"au\",\n",
    "}\n",
    "syllables = []\n",
    "for cons in consonants:\n",
    "    for sign, label in vowel_signs.items():\n",
    "        syllable = cons + sign\n",
    "        syllables.append(syllable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = list(map(lambda x: len(list(x.encode())), syllables))\n",
    "set(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of malayalam chars : 128\n",
      "First entry: ((224, 180, 128), 256)\n",
      "Last entry: ((224, 181, 191), 383)\n",
      "First entry: ((224, 180, 149, 224, 180, 190), 384)\n",
      "Last entry: ((224, 180, 185, 224, 181, 140), 827)\n"
     ]
    }
   ],
   "source": [
    "# Creating a new mapping starting from 256 to encode all malayalam chars\n",
    "malayalam_chars_mapping = {tuple(char.encode(\"utf-8\")) : 256+i   for i, char in enumerate(malayalam_chars)}\n",
    "print(f\"length of malayalam chars : {len(malayalam_chars_mapping)}\")\n",
    "print(f\"First entry: {sorted([(k,v) for k, v in malayalam_chars_mapping.items()], key=lambda x: x[1])[0]}\")\n",
    "print(f\"Last entry: {sorted([(k,v) for k, v in malayalam_chars_mapping.items()], key=lambda x: x[1])[-1]}\")\n",
    "malayalam_syllabeles_mapping = {tuple(char.encode(\"utf-8\")) : 256+len(malayalam_chars_mapping)+i   for i, char in enumerate(syllables)}\n",
    "print(f\"First entry: {sorted([(k,v) for k, v in malayalam_syllabeles_mapping.items()], key=lambda x: x[1])[0]}\")\n",
    "print(f\"Last entry: {sorted([(k,v) for k, v in malayalam_syllabeles_mapping.items()], key=lambda x: x[1])[-1]}\")\n",
    "\n",
    "vocabulary = {v: bytes(k).decode() for k, v in malayalam_chars_mapping.items()}\n",
    "vocabulary.update({v: bytes(k).decode() for k, v in malayalam_syllabeles_mapping.items()})\n",
    "\n",
    "with open(\"../malayalam_chars_mapping.pkl\", \"wb\") as f:\n",
    "    pickle.dump(malayalam_chars_mapping, f)\n",
    "\n",
    "with open(\"../malayalam_syllabeles_mapping.pkl\", \"wb\") as f:\n",
    "    pickle.dump(malayalam_syllabeles_mapping, f)\n",
    "\n",
    "def decode_malayalam_char_ids(ids: list[int]) -> str:\n",
    "    \"\"\"Take a list of malayalam char ids and return the corresponding malayalam string\"\"\"\n",
    "    return \"\".join([vocabulary.get(id) for id in ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(ids: list[int]) -> dict[tuple[int, int], int]:\n",
    "    \"\"\"Takes a list of ints and find the occurance of each pair\"\"\"\n",
    "    counts = {}\n",
    "    for pair in zip(ids, ids[1:]):\n",
    "        counts[pair] = counts.get(pair, 0) + 1\n",
    "    return counts\n",
    "\n",
    "def get_top_pair(stats: dict) -> tuple[int, int]:\n",
    "    \"\"\"Find the most occuring pair\"\"\"\n",
    "    return max(stats, key=stats.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_malayalam_char_tokens(tokens: list[int]) -> list[int]:\n",
    "    \"\"\"Merge UTF-8 byte sequences into new vocab ids for Malayalam characters\"\"\"\n",
    "    merged_tokens = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        if i + 2 < len(tokens):  # check if 3 bytes available\n",
    "            key = (tokens[i], tokens[i+1], tokens[i+2])\n",
    "            value = malayalam_chars_mapping.get(key)\n",
    "            if value is not None:\n",
    "                merged_tokens.append(value)\n",
    "                i += 3\n",
    "                continue\n",
    "        # fallback: keep single byte\n",
    "        merged_tokens.append(tokens[i])\n",
    "        i += 1\n",
    "    return merged_tokens\n",
    "\n",
    "def merge_malayalam_syllabele_tokens(tokens: list[int]) -> list[int]:\n",
    "    \"\"\"Merge UTF-8 byte sequences into new vocab ids for Malayalam characters\"\"\"\n",
    "    merged_tokens = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        if i + 5 < len(tokens):  # check if 6 bytes available syllabele is always 6 bytes\n",
    "            key = (tokens[i], tokens[i+1], tokens[i+2], tokens[i+3], tokens[i+4], tokens[i+5])\n",
    "            value = malayalam_syllabeles_mapping.get(key)\n",
    "            if value is not None:\n",
    "                merged_tokens.append(value)\n",
    "                i += 6\n",
    "                continue\n",
    "        # fallback: keep single byte\n",
    "        merged_tokens.append(tokens[i])\n",
    "        i += 1\n",
    "    return merged_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[224, 180, 150, 224, 180, 191]\n",
      "[397]\n",
      "[397]\n",
      "ഖി\n"
     ]
    }
   ],
   "source": [
    "text = \"ഖി\"\n",
    "tokens = list(text.encode(\"utf-8\"))\n",
    "print(tokens)\n",
    "updated_tokens = merge_malayalam_syllabele_tokens(tokens)\n",
    "print(updated_tokens)\n",
    "updated_tokens = merge_malayalam_char_tokens(updated_tokens)\n",
    "print(updated_tokens)\n",
    "print(decode_malayalam_char_ids(updated_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pair(tokens, pair_to_merge, new_idx):\n",
    "    \"\"\"Merge common pairs to create new pairs\"\"\"\n",
    "    merged_tokens = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        if i < len(tokens)-1 and (tokens[i], tokens[i+1]) == pair_to_merge:\n",
    "            merged_tokens.append(new_idx)\n",
    "            i += 2\n",
    "        else:\n",
    "            merged_tokens.append(tokens[i])\n",
    "            i += 1\n",
    "    return merged_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../dataset/output.json\", \"r\") as f:\n",
    "    ds = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6050956"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763524\n",
      "അപകടങ്ങള്‍ നേരിടാന്‍ എപ്പോഴും സജ്ജരായിരിക്കണം.ഞങ്ങള്‍ തമ്മില്‍ വ്യക്തിപരമായ അഭിപ്രായവ്യത്യാസമൊന്നുമില്ല.സഹിക്കാന്‍ കയുന്നതിന് പരിധിയുണ്ട്.ഇന്ത്യന്‍ എംബസി ഇടപെട്ട കാരണമാണ് മോചനം സാധ്യമായത്.ഒരു കാര്യം ഓര്‍മിപ്പിക്കട്ടെ...12,816 എന്ന നിലയിൽ ഗാപ് അപ്പോടെ നിഫ്റ്റി തുറന്നു, വളരെ അധികം നേരം ഏകീകരിച്ചു.കമ്മീഷന്റെ അന്വ .പിതൃസഹോദരനും പാര്‍ട്ടി സംസ്ഥാന അധ്യക്ഷനുമായ ശിവ്പാല്‍ യാദവ് ഉള്‍പ്പെടെ നാലു പേരെ മുഖ്യമന്ത്രി അഖിലേഷ് യാദവ് മന്ത്രിസഭയില്‍ നിന്നു പുറത്താക്കിയതിന് തൊട്ടുപിന്നാലെ അഖിലേഷിന്‍റെ അനുയായിയും പാര്‍ട്ടി ജനറല്‍ സെക്രട്ടറിയുമായ രാംഗോപാല്‍ യാദവിനെ ശിവ്പാല്‍ യാദവ് ആറു വര്‍ഷത്തേക്ക് പാര്‍ട്ടിയില്‍ നിന്നു പുറത്താക്കിയതോടെയാണ് സമാജ്‌വാദി പാര്‍ട്ടിയില്‍ പ്രതിസന്ധി രൂക്ഷമായത്.അയാള്‍ പറഞ്ഞു എന്റെ അച്ഛനാണ് അയാളുടെ വീട്ടിലെ കര്‍മ്മങ്ങളെല്ലാം ചെയ്തിരുന്നതെന്ന്ആശുപത്രിയിൽ വച്ചാണ് ഇയാൾ മരിച്ചിരിക്കുന്നത്.മതി താപനില 80-90 ഡിഗ്രി ആണ്.ദില്ലി/വാഷിംഗ്ടണ്‍: ചൈനയുമായി അതിര്‍ത്തിയില്‍ നടക്കുന്ന സംഘര്‍ഷങ്ങളില്‍ മോദി സന്തുഷ്ടനല്ലെന്ന് ഡൊണാള്‍ഡ് ട്രംപ്കരുതിക്കൂട്ടി ചെയ്യുന്നതുമല്ല.\"\"\"കുഴൽ വിഴുങ്ങിക്കോളൂ.\"65 ഓളം\n"
     ]
    }
   ],
   "source": [
    "text = \"\".join(ds[:10000])\n",
    "print(len(text))\n",
    "print(text[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal number of tokens : 2106330\n",
      "Number of tokens after merging  syllable vocabulary (like ക, കാ, കി, കീ …): 1344545, 0.36\n",
      "Number of tokens after merging  all malayalm chars: 636675, 0.70, 0.53\n"
     ]
    }
   ],
   "source": [
    "tokens = list(text.encode(\"utf-8\")) # Text to list of ints between 0-255\n",
    "l1 = len(tokens)\n",
    "print(f\"Orginal number of tokens : {len(tokens)}\")\n",
    "tokens = merge_malayalam_syllabele_tokens(tokens) \n",
    "l2 = len(tokens)\n",
    "print(f\"Number of tokens after merging  syllable vocabulary (like ക, കാ, കി, കീ …): {len(tokens)}, {(l1-l2)/l1:.2f}\")\n",
    "tokens = merge_malayalam_char_tokens(tokens)\n",
    "l3 = len(tokens)\n",
    "print(f\"Number of tokens after merging  all malayalm chars: {len(tokens)}, {(l1-l3)/l1:.2f}, {(l2-l3)/l2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New num of tokens : 4173\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f1de6dab9b2415ebc32d8b4fc9a5106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4173 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_chars_mapping = {}\n",
    "\n",
    "final_vocab_size = 5000\n",
    "current_vocab_size = 255 + len(malayalam_chars_mapping) + len(malayalam_syllabeles_mapping)\n",
    "num_merges = final_vocab_size - current_vocab_size\n",
    "print(f\"New num of tokens : {num_merges}\")\n",
    "token_ids = list(tokens)\n",
    "\n",
    "for i in tqdm(range(num_merges)):\n",
    "    stats = get_stats(token_ids)\n",
    "    pair = max(stats, key=stats.get)\n",
    "    idx = current_vocab_size + 1 + i\n",
    "    token_ids = merge_pair(token_ids, pair, idx)\n",
    "    merged_chars_mapping[pair] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../merged_chars_mapping.pkl\", \"wb\") as f:\n",
    "    pickle.dump(merged_chars_mapping, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ത്ഥ'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_merged_chars_mapping = {v: k for k, v in merged_chars_mapping.items()}\n",
    "\n",
    "def decode_merged_chars_mapping(token_id: int) -> str:\n",
    "\n",
    "    if token_id < 256:\n",
    "        return chr(token_id)\n",
    "    \n",
    "    if token_id in vocabulary:\n",
    "        return vocabulary[token_id]\n",
    "    \n",
    "    id1, id2 = reverse_merged_chars_mapping.get(token_id)\n",
    "    char1 = decode_merged_chars_mapping(id1)\n",
    "    char2 = decode_merged_chars_mapping(id2)\n",
    "    return char1 + char2\n",
    "    \n",
    "\n",
    "decode_merged_chars_mapping(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vocabulary = {v: decode_merged_chars_mapping(v) for v in merged_chars_mapping.values()}\n",
    "vocabulary.update(new_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../vocabulary.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vocabulary, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "make-more",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
