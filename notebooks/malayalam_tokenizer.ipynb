{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ഀ', 'ഁ', 'ം', 'ഃ', 'ഄ', 'അ', 'ആ', 'ഇ', 'ഈ', 'ഉ'],\n",
       " ['൶', '൷', '൸', '൹', 'ൺ', 'ൻ', 'ർ', 'ൽ', 'ൾ', 'ൿ'],\n",
       " 128)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collecting all the malayalam chars\n",
    "malayalam_chars = [chr(code) for code in range(0x0D00, 0x0D7F + 1)]\n",
    "malayalam_chars[:10], malayalam_chars[-10:], len(malayalam_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new mapping starting from 256 to encode all malayalam chars\n",
    "malayalam_chars_mapping = {tuple(char.encode(\"utf-8\")) : 256+i   for i, char in enumerate(malayalam_chars)}\n",
    "\n",
    "vocabulary = {v: bytes(k).decode() for k, v in malayalam_chars_mapping.items()}\n",
    "\n",
    "with open(\"../malayalam_chars_mapping.pkl\", \"wb\") as f:\n",
    "    pickle.dump(malayalam_chars_mapping, f)\n",
    "\n",
    "def decode_malayalam_char_ids(ids: list[int]) -> str:\n",
    "    \"\"\"Take a list of malayalam char ids and return the corresponding malayalam string\"\"\"\n",
    "    return \"\".join([vocabulary.get(id) for id in ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(ids: list[int]) -> dict[tuple[int, int], int]:\n",
    "    \"\"\"Takes a list of ints and find the occurance of each pair\"\"\"\n",
    "    counts = {}\n",
    "    for pair in zip(ids, ids[1:]):\n",
    "        counts[pair] = counts.get(pair, 0) + 1\n",
    "    return counts\n",
    "\n",
    "def get_top_pair(stats: dict) -> tuple[int, int]:\n",
    "    \"\"\"Find the most occuring pair\"\"\"\n",
    "    return max(stats, key=stats.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_tokens(tokens: list[int], malayalam_chars_vocab: dict[tuple[int, int, int], int]) -> list[int]:\n",
    "    \"\"\"Merge UTF-8 byte sequences into new vocab ids for Malayalam characters\"\"\"\n",
    "    merged_tokens = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        if i + 2 < len(tokens):  # check if 3 bytes available\n",
    "            key = (tokens[i], tokens[i+1], tokens[i+2])\n",
    "            value = malayalam_chars_vocab.get(key)\n",
    "            if value is not None:\n",
    "                merged_tokens.append(value)\n",
    "                i += 3\n",
    "                continue\n",
    "        # fallback: keep single byte\n",
    "        merged_tokens.append(tokens[i])\n",
    "        i += 1\n",
    "    return merged_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[224, 180, 133, 224, 180, 150, 224, 180, 191, 224, 181, 189]\n",
      "[261, 278, 319, 381]\n",
      "അഖിൽ\n"
     ]
    }
   ],
   "source": [
    "text = \"അഖിൽ\"\n",
    "tokens = list(text.encode(\"utf-8\"))\n",
    "print(tokens)\n",
    "updated_tokens = update_tokens(tokens, malayalam_chars_mapping)\n",
    "print(updated_tokens)\n",
    "print(decode_malayalam_char_ids(updated_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pair(tokens, pair_to_merge, new_idx):\n",
    "    \"\"\"Merge common pairs to create new pairs\"\"\"\n",
    "    merged_tokens = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        if i < len(tokens)-1 and (tokens[i], tokens[i+1]) == pair_to_merge:\n",
    "            merged_tokens.append(new_idx)\n",
    "            i += 2\n",
    "        else:\n",
    "            merged_tokens.append(tokens[i])\n",
    "            i += 1\n",
    "    return merged_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../dataset/output.json\", \"r\") as f:\n",
    "    ds = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6050956"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74284\n",
      "അപകടങ്ങള്‍ നേരിടാന്‍ എപ്പോഴും സജ്ജരായിരിക്കണം.ഞങ്ങള്‍ തമ്മില്‍ വ്യക്തിപരമായ അഭിപ്രായവ്യത്യാസമൊന്നുമില്ല.സഹിക്കാന്‍ കയുന്നതിന് പരിധിയുണ്ട്.ഇന്ത്യന്‍ എംബസി ഇടപെട്ട കാരണമാണ് മോചനം സാധ്യമായത്.ഒരു കാര്യം ഓര്‍മിപ്പിക്കട്ടെ...12,816 എന്ന നിലയിൽ ഗാപ് അപ്പോടെ നിഫ്റ്റി തുറന്നു, വളരെ അധികം നേരം ഏകീകരിച്ചു.കമ്മീഷന്റെ അന്വ .പിതൃസഹോദരനും പാര്‍ട്ടി സംസ്ഥാന അധ്യക്ഷനുമായ ശിവ്പാല്‍ യാദവ് ഉള്‍പ്പെടെ നാലു പേരെ മുഖ്യമന്ത്രി അഖിലേഷ് യാദവ് മന്ത്രിസഭയില്‍ നിന്നു പുറത്താക്കിയതിന് തൊട്ടുപിന്നാലെ അഖിലേഷിന്‍റെ അനുയായിയും പാര്‍ട്ടി ജനറല്‍ സെക്രട്ടറിയുമായ രാംഗോപാല്‍ യാദവിനെ ശിവ്പാല്‍ യാദവ് ആറു വര്‍ഷത്തേക്ക് പാര്‍ട്ടിയില്‍ നിന്നു പുറത്താക്കിയതോടെയാണ് സമാജ്‌വാദി പാര്‍ട്ടിയില്‍ പ്രതിസന്ധി രൂക്ഷമായത്.അയാള്‍ പറഞ്ഞു എന്റെ അച്ഛനാണ് അയാളുടെ വീട്ടിലെ കര്‍മ്മങ്ങളെല്ലാം ചെയ്തിരുന്നതെന്ന്ആശുപത്രിയിൽ വച്ചാണ് ഇയാൾ മരിച്ചിരിക്കുന്നത്.മതി താപനില 80-90 ഡിഗ്രി ആണ്.ദില്ലി/വാഷിംഗ്ടണ്‍: ചൈനയുമായി അതിര്‍ത്തിയില്‍ നടക്കുന്ന സംഘര്‍ഷങ്ങളില്‍ മോദി സന്തുഷ്ടനല്ലെന്ന് ഡൊണാള്‍ഡ് ട്രംപ്കരുതിക്കൂട്ടി ചെയ്യുന്നതുമല്ല.\"\"\"കുഴൽ വിഴുങ്ങിക്കോളൂ.\"65 ഓളം\n"
     ]
    }
   ],
   "source": [
    "text = \"\".join(ds[:1000])\n",
    "print(len(text))\n",
    "print(text[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = list(text.encode(\"utf-8\")) # Text to list of ints between 0-255\n",
    "tokens = update_tokens(tokens, malayalam_chars_mapping) # Update to new vocab ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "547a9262b9904b61afc1a2c85ea3bf03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/617 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_chars_mapping = {}\n",
    "\n",
    "final_vocab_size = 1000\n",
    "current_vocab_size = 255 + len(malayalam_chars_mapping) \n",
    "num_merges = final_vocab_size - current_vocab_size\n",
    "token_ids = list(tokens)\n",
    "\n",
    "for i in tqdm(range(num_merges)):\n",
    "    stats = get_stats(token_ids)\n",
    "    pair = max(stats, key=stats.get)\n",
    "    idx = current_vocab_size + 1 + i\n",
    "    token_ids = merge_pair(token_ids, pair, idx)\n",
    "    merged_chars_mapping[pair] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../merged_chars_mapping.pkl\", \"wb\") as f:\n",
    "    pickle.dump(merged_chars_mapping, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'് '"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_merged_chars_mapping = {v: k for k, v in merged_chars_mapping.items()}\n",
    "\n",
    "def decode_merged_chars_mapping(token_id: int) -> str:\n",
    "\n",
    "    if token_id < 256:\n",
    "        return chr(token_id)\n",
    "        # return bytes([token_id]).decode(\"utf-8\")\n",
    "    \n",
    "    if token_id in vocabulary:\n",
    "        return vocabulary[token_id]\n",
    "    \n",
    "    id1, id2 = reverse_merged_chars_mapping.get(token_id)\n",
    "    char1 = decode_merged_chars_mapping(id1)\n",
    "    char2 = decode_merged_chars_mapping(id2)\n",
    "    return char1 + char2\n",
    "    \n",
    "\n",
    "decode_merged_chars_mapping(390)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary.update({v: decode_merged_chars_mapping(v) for v in merged_chars_mapping.values()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../vocabulary.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vocabulary, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "make-more",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
